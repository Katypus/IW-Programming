Device set to use cuda:0
Device set to use cuda:0
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
Traceback (most recent call last):
  File "/home/kr5379/IW-Programming-1/sent_anal_gen.py", line 46, in <module>
    emotion_results = emotion_analyzer(emotion_dataset, batch_size=16, function_to_apply=None, input_columns="text")
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/text_classification.py", line 159, in __call__
    result = super().__call__(*inputs, **kwargs)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/base.py", line 1371, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/base.py", line 1377, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/text_classification.py", line 183, in preprocess
    return self.tokenizer(inputs, return_tensors=return_tensors, **tokenizer_kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/tokenization_utils_base.py", line 2947, in _call_one
    raise ValueError(
    ...<2 lines>...
    )
ValueError: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).
Device set to use cuda:0
Device set to use cuda:0
Traceback (most recent call last):
  File "/home/kr5379/IW-Programming-1/sent_anal_gen.py", line 46, in <module>
    emotion_results = emotion_analyzer(emotion_dataset, batch_size=16, function_to_apply=None, input_columns="text")
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/text_classification.py", line 159, in __call__
    result = super().__call__(*inputs, **kwargs)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/base.py", line 1371, in __call__
    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/base.py", line 1377, in run_single
    model_inputs = self.preprocess(inputs, **preprocess_params)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/pipelines/text_classification.py", line 183, in preprocess
    return self.tokenizer(inputs, return_tensors=return_tensors, **tokenizer_kwargs)
           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/tokenization_utils_base.py", line 2887, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
  File "/home/kr5379/.conda/envs/sentiment/lib/python3.13/site-packages/transformers/tokenization_utils_base.py", line 2947, in _call_one
    raise ValueError(
    ...<2 lines>...
    )
ValueError: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).
